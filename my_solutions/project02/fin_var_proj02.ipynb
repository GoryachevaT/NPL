{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ[\"PYSPARK_SUBMIT_ARGS\"]='pyspark-shell'\n",
    "os.environ[\"PYSPARK_PYTHON\"]='/opt/anaconda/envs/bd9/bin/python'\n",
    "os.environ[\"SPARK_HOME\"]='/usr/hdp/current/spark2-client'\n",
    "\n",
    "spark_home = os.environ.get('SPARK_HOME', None)\n",
    "if not spark_home:\n",
    "    raise ValueError('SPARK_HOME environment variable is not set')\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python'))\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python/lib/py4j-0.10.7-src.zip'))\n",
    "exec(open(os.path.join(spark_home, 'python/pyspark/shell.py')).read())\n",
    "# from pyspark.mllib.feature import HashingTF, IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import functions as F   \n",
    "\n",
    "from pyspark.sql import SQLContext\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#тестовые товары\n",
    "\n",
    "test_schema = StructType(fields=[StructField(\"item\",StringType()),\n",
    "                                StructField(\"true_recoms\",StringType())#MapType(StringType(), IntegerType()))\n",
    "                                ])\n",
    "ozon_train = spark.read.json(\"/labs/project02/ozon_train.txt\",schema=test_schema)\n",
    "ozon_train.registerTempTable('ozon_train')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ozon_train.toPandas().to_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#тестовые товары\n",
    "\n",
    "test_schema = StructType(fields=[StructField(\"item\",StringType()),\n",
    "                                ])\n",
    "ozon_test = spark.read.json(\"/labs/project02/ozon_test.txt\",schema=test_schema)\n",
    "ozon_test.registerTempTable('ozon_test')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ozon_test.toPandas().to_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "from tqdm import tqdm\n",
    "from lightfm import LightFM\n",
    "from lightfm.data import Dataset\n",
    "from lightfm.evaluation import precision_at_k, recall_at_k\n",
    "from lightfm.evaluation import auc_score\n",
    "\n",
    "%matplotlib inline\n",
    "pd.set_option('max_rows',200)\n",
    "pd.set_option('max_columns',200)\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# catalogs.csv255 MB6 минут назад\n",
    "# ozon_test.txt2.24 MB19 часов назад\n",
    "# ozon_train.txt19.1 MB19 часов назад\n",
    "# test.csv889 kBнесколько секунд назад\n",
    "# train.csv16.4 MBнесколько секунд назад\n",
    "# train_exploded.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# catalogs = pd.read_csv('catalogs.csv',dtype=str).drop('Unnamed: 0',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# catalog_path = pd.read_csv('catalog_path.csv',dtype=str).drop('Unnamed: 0',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv',dtype=str).drop('Unnamed: 0',axis=1)\n",
    "test = pd.read_csv('test.csv',dtype=str).drop('Unnamed: 0',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[train['true_recoms'].map(json.loads).map(lambda x: len(x.keys()))<200]\n",
    "train['true_recoms'] = train['true_recoms'].map(json.loads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "_ = train.apply(lambda row: [rows.append([row['item'], nn, row['true_recoms'][nn]]) \n",
    "                         for nn in row['true_recoms']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_new = pd.DataFrame(rows, columns=['item','item_rec','count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset()\n",
    "dataset.fit(users = (x for x in train_new['item']),\n",
    "            items = (x for x in train_new['item_rec'])\n",
    "           )\n",
    "# dataset.fit_partial(users = (x for x in train_new['item_rec']),\n",
    "#             items = (x for x in train_new['item_rec'])\n",
    "#            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "(interactions, weights) = dataset.build_interactions(((x[1]['item'], x[1]['item_rec'], x[1]['count'])\n",
    "                                                      for x in train_new.iterrows()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4059856e389a48beadaab2cb87d2cd10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=50), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from lightfm import LightFM\n",
    "from IPython.display import clear_output\n",
    "from lightfm.evaluation import precision_at_k, recall_at_k, auc_score\n",
    "model = LightFM(no_components=16, learning_rate=0.04, loss='warp', max_sampled=100, random_state=0)\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "num_epochs = 50\n",
    "for i in tqdm_notebook(range(num_epochs), total=num_epochs):\n",
    "    model.fit_partial(\n",
    "        interactions\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142437 142437 337756 337756\n",
      "Num user features: 0 -> 142437\n",
      "num asset features: 0 -> 337756.\n",
      "142437 337756\n"
     ]
    }
   ],
   "source": [
    "num_users, num_items = dataset.interactions_shape()\n",
    "users_mapping, user_features_mapping, assets_mapping, asset_features_mapping = dataset.mapping()\n",
    "print(len(users_mapping), len(user_features_mapping),len(assets_mapping), len(asset_features_mapping))\n",
    "num_user_features = dataset.user_features_shape()\n",
    "num_asset_features = dataset.item_features_shape()\n",
    "print('Num user features: {} -> {}\\nnum asset features: {} -> {}.'.format(num_user_features[1] - num_users, num_user_features[1], num_asset_features[1] - num_items, num_asset_features[1]))\n",
    "print(len(user_features_mapping), len(asset_features_mapping))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60956, 1)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c347847788b46c496bfc16e01ebc006",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "with open('~/project02.txt', 'a') as f:\n",
    "    for row in tqdm_notebook(test.iterrows()):\n",
    "        obj = row[1]['item']\n",
    "        if obj in asset_features_mapping:\n",
    "            asset_features_mapping_inv = {j:i for i,j in asset_features_mapping.items()}\n",
    "            def get_similar_tags(model, tag_id):\n",
    "                # Define similarity as the cosine of the angle\n",
    "                # between the tag latent vectors\n",
    "\n",
    "                # Normalize the vectors to unit length\n",
    "                tag_embeddings = (model.item_embeddings.T\n",
    "                                  / np.linalg.norm(model.item_embeddings, axis=1)).T\n",
    "\n",
    "                query_embedding = tag_embeddings[tag_id]\n",
    "                similarity = np.dot(tag_embeddings, query_embedding)\n",
    "                most_similar = np.argsort(-similarity)[1:101]\n",
    "\n",
    "                return most_similar,(similarity)[most_similar]\n",
    "\n",
    "\n",
    "            tag_id = asset_features_mapping[obj]\n",
    "            similar,similarity = get_similar_tags(model, tag_id)\n",
    "\n",
    "            similar = [asset_features_mapping_inv[x] for x in similar]\n",
    "\n",
    "            f.write(json.dumps({\"item\":obj,\"recoms\":{i:float(j) for i, j in zip(similar,similarity)}})+'\\n')\n",
    "        else:\n",
    "#             print(obj) 6242189\n",
    "            f.write(json.dumps({\"item\":obj,\"recoms\":{}})+'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !cp project02.txt ~/project02.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def similar_items(item_id, item_features, model, N=10):\n",
    "#     item_representations = item_features.dot(model.item_embeddings)\n",
    "\n",
    "#     # Cosine similarity\n",
    "#     scores = item_representations.dot(item_representations[item_id, :])\n",
    "#     item_norms = np.linalg.norm(item_representations, axis=1)\n",
    "#     scores /= item_norms\n",
    "\n",
    "#     best = np.argpartition(scores, -N)[-N:]\n",
    "#     return sorted(zip(best, scores[best] / item_norms[item_id]), \n",
    "#                   key=lambda x: -x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
