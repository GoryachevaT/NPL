{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import sys, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to\n",
      "      ____              __\n",
      "     / __/__  ___ _____/ /__\n",
      "    _\\ \\/ _ \\/ _ `/ __/  '_/\n",
      "   /__ / .__/\\_,_/_/ /_/\\_\\   version 2.4.3\n",
      "      /_/\n",
      "\n",
      "Using Python version 3.6.5 (default, Apr 29 2018 16:14:56)\n",
      "SparkSession available as 'spark'.\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"PYSPARK_SUBMIT_ARGS\"]='--conf spark.sql.catalogImplementation=in-memory pyspark-shell'\n",
    "os.environ[\"PYSPARK_PYTHON\"]='/opt/anaconda/envs/bd9/bin/python'\n",
    "os.environ[\"SPARK_HOME\"]='/usr/hdp/current/spark2-client'\n",
    "\n",
    "spark_home = os.environ.get('SPARK_HOME', None)\n",
    "if not spark_home:\n",
    "    raise ValueError('SPARK_HOME environment variable is not set')\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python'))\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python/lib/py4j-0.10.7-src.zip'))\n",
    "exec(open(os.path.join(spark_home, 'python/pyspark/shell.py')).read())\n",
    "\n",
    "\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import udf, concat_ws\n",
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer, CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#описание и характеристики товаров магазина\n",
    "data = spark.read.json('/labs/project02/item_details_full')\n",
    "data=data.dropDuplicates().fillna(' ')                \n",
    "data.registerTempTable('item_details_full')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!hadoop fs -cat /labs/project02/item_details_full | head -n 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "item = data.select(\n",
    "       data.itemid.cast('integer'), \n",
    "       data.parent_id.cast('integer'), \n",
    "       concat_ws(' ', *['attr' + str(x) for x in range(78)]).alias('text'))\n",
    "\n",
    "item.registerTempTable('item') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(itemid=24489143, parent_id=None, text='Traite de la methode fumigatoire, ou, De l\\'emploi medical des bains et douches de vapeurs. Воспроизведено в оригинальной авторской орфографии издания 1824 года (издательство \"A Paris : Chez Gabon\").   Traite de la methode fumigatoire, ou, De l\\'emploi medical des bains et douches de vapeurs   Toussaint Rapou                                 Книга по Требованию                              Французский                                            978_5_8727_2685_2                                                  '),\n",
       " Row(itemid=23888213, parent_id=23496357, text='Современные кроссовки от Nike непременно станут вашими верными спутниками. Верх модели выполнен из натуральной кожи черного цвета и дополнен прострочкой. Боковые части модели дополнены вышивкой в виде логотипа бренда. Удобная шнуровка не только отлично смотрится, но и превосходно фиксирует модель на ноге. Внутри - отделка из текстиля. Плотная оригинальная подошва с амортизатором обеспечивает оптимальный комфорт.   Кроссовки Nike 325201. Цвет: Черный. Размер 40.                   Nike                                                          Муж.                                                                                ')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# id товара - id каталога\n",
    "schema_t = StructType(fields=[StructField(\"itemid\",StringType()),\n",
    "                              StructField(\"catalogid\",StringType())\n",
    "                             ])\n",
    "catalogs = spark.read.json(\"/labs/project02/catalogs\",schema=schema_t)\n",
    "catalogs.registerTempTable('catalogs')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# товары + каталоги, к которым они относятся\n",
    "item_cat = spark.sql('''SELECT trim(a.text) as attr,\n",
    "                            a.itemid,\n",
    "                            b.catalogid \n",
    "                     FROM item a \n",
    "                     JOIN catalogs b \n",
    "                       on a.itemid = b.itemid\n",
    "                  ''')\n",
    "item_cat.registerTempTable('item_cat') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Токенизация\n",
    "@F.udf(ArrayType(StringType()))\n",
    "def tokenizer(text):\n",
    "    regex = re.compile(r'[\\w\\d]', re.U)\n",
    "    text = text.lower()\n",
    "    return regex.findall(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_words_udf = item_cat.withColumn('words', tokenizer('attr'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "htf = HashingTF(inputCol=\"words\",\n",
    "                outputCol=\"TFFeatures\")\n",
    "feats = htf.transform(df_with_words_udf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "idf = IDF(inputCol=\"TFFeatures\", outputCol=\"features\")\n",
    "idfModel = idf.fit(feats)\n",
    "upd_df = idfModel.transform(feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Normalizer\n",
    "t = Normalizer(inputCol='features', outputCol='norm_features', p=2.0)\n",
    "upd_df_2 = t.transform(upd_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "upd_df_2 = upd_df_2.drop('attr','words','TFFeatures', 'features').cache()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "upd_df_2.registerTempTable('feats')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(itemid=64423, catalogid='1133234', norm_features=SparseVector(262144, {10108: 0.0704, 15554: 0.0253, 17222: 0.0147, 24417: 0.0145, 34719: 0.0442, 34893: 0.0354, 47875: 0.2953, 52032: 0.5579, 58109: 0.0432, 62423: 0.2106, 66836: 0.1042, 67583: 0.2472, 70917: 0.1554, 80176: 0.2023, 95457: 0.0543, 105732: 0.1832, 105964: 0.0734, 107349: 0.0431, 109465: 0.0162, 113838: 0.0455, 118126: 0.0733, 132812: 0.0729, 145084: 0.1739, 147580: 0.1548, 147711: 0.2, 157485: 0.1697, 162209: 0.0269, 165164: 0.0624, 174135: 0.0621, 174776: 0.1688, 182498: 0.0088, 213268: 0.0284, 227410: 0.0143, 230215: 0.0251, 233878: 0.0259, 234682: 0.1052, 236968: 0.1605, 237265: 0.0351, 240533: 0.3894, 250208: 0.0167}))]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upd_df_2.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nИскать похожие товары непосредственно в том же каталоге, где находится и основной товар. \\nСравнивать (краткое описание + основные характеристики) товаров косинусной мерой, \\nгде мера похожести будет соответствовать весу рекомендуемого товара\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ИНСАЙТ ОТ МОИХ КОЛЛЕГ, которые ходили на прошлый выпуск NPL\n",
    "#они сказали, что такой подход сработал: \n",
    "\n",
    "'''\n",
    "Искать похожие товары непосредственно в том же каталоге, где находится и основной товар. \n",
    "Сравнивать (краткое описание + основные характеристики) товаров косинусной мерой, \n",
    "где мера похожести будет соответствовать весу рекомендуемого товара\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#тестовые товары\n",
    "test_schema = StructType(fields=[StructField(\"item\",StringType())])\n",
    "item_test = spark.read.json(\"/labs/project02/ozon_test.txt\",schema=test_schema)\n",
    "item_test.registerTempTable('test')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#берем товары из теста\n",
    "#catalogs - таблица из \"/labs/project02/catalogs\"\n",
    "item_cat_test = spark.sql('select * from catalogs where itemid in (SELECT item FROM test)') \n",
    "item_cat_test.registerTempTable('item_cat_test') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#берем уникальные id каталогов, чтобы далее по ним пройтись\n",
    "cats = spark.sql('select distinct catalogid from item_cat_test ')\n",
    "cats = cats.toPandas() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats_ids = [int(cat) for cat in cats['catalogid'].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('project02.txt','w') as f:\n",
    "    for i in tqdm(cats_ids):  #проходим по каталогам\n",
    "        feats = spark.sql('select * from feats where catalogid={}'.format(i))            \n",
    "        feats.cache()  \n",
    "        feats.registerTempTable('feats_i') \n",
    "        short_item_cat_test = item_cat_test.filter('catalogid={}'.format(i)) #отберём товары теста текущей группы\n",
    "        short_item_cat_test = short_item_cat_test.toPandas() \n",
    "        for i in tqdm(range(short_item_cat_test['itemid'].count())): \n",
    "            row = spark.sql('SELECT * FROM feats_i WHERE itemid={}'.format(short_item_cat_test['itemid'][i]))\\\n",
    "                                                                          .first()\n",
    "            # для каждого row найдём косинусную меру товаров из его (товара из теста) группы\n",
    "            #нужно получить resultData['itemid','similarity']\n",
    "            \n",
    "            pn={'item' : short_item_cat_test['itemid'][i],\n",
    "                'recoms': {r.itemid : r.similarity for r in resultData[['itemid','similarity']].take(101)[0:100]}}\n",
    "            f.write(str(pn).replace(\"'\",'\"')+'\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
